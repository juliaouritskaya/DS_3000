{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79f695be",
   "metadata": {},
   "source": [
    "# DS 3000 - Lab 10: Classification Trees\n",
    "\n",
    "**Student Name**: [Julia Ouritskaya]\n",
    "\n",
    "**Date**: [11/10/2023]\n",
    "\n",
    "### Submission Instructions\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "In this lab you will you'll work the [iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set) and train your first classification tree. The dataset is already loaded in your environment. Complete the questions in the lab and submit this `ipynb` file with your solution.\n",
    "</div>\n",
    "\n",
    "`Note:` The `ipynb` format stores outputs from the last time you ran the notebook. When you open a notebook it has the figures and outputs of the last time you ran it.  To ensure that your submitted `ipynb` file represents your latest code, make sure to give a fresh run `Kernel > Restart & Run All` just before uploading the `ipynb` file to Gradescope.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "Please do not delete the cells that are provided nor add any extra cells. Ensure that you write your code in the given cells where indicated. <br>\n",
    "<strong>Do not delete any empty cells.</strong><br>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4693f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import any Libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262fc746",
   "metadata": {},
   "source": [
    "### Question 1: Load the data (0 pts)\n",
    "In this question you will load the iris data (this was performed for you). DO NOT change the names of the input 'X' and the labels 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b3ab47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data from sklearn.datasets\n",
    "data     = load_iris()\n",
    "\n",
    "#divide the data into the input 'X' and the labels 'y'\n",
    "X        = data['data'] #the observations\n",
    "y        = data['target'] #the label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5589bd7a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5177a9c919c62e7536679f23a6b0506",
     "grade": true,
     "grade_id": "test_values",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#DO NOT DELETE THIS CELL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8178a923",
   "metadata": {},
   "source": [
    "### Question 2: partition the data (1 pt)\n",
    "\n",
    "Complete the function `partition_data(...)`. The function takes as input `X`, `y`, and `seed`. Ensure that you perform the following steps inside the function:\n",
    "- Split the data (i.e. X and y) into 80% train and 20% test.\n",
    "- Ensure that your partitions are **stratified** and **reproducible**.\n",
    "- Return the resulting features for X_train and X_test; and the labels for y_train and y_test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71494000",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "914abac9",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2730133dfd8976c04279fa1bdc933e31",
     "grade": false,
     "grade_id": "partition_data",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def partition_data(X: np.ndarray, y: np.ndarray, seed: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Input numpy arrays for X and y.\n",
    "\n",
    "    Parameters:\n",
    "    - X (np.ndarray): a numpy array that contains the explanatory variables\n",
    "    - y (np.ndarray): a numpy array that contains the target variable\n",
    "    - seed(integer): the random state for reproducibilty\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: X_train, X_test, y_train, y_test #Ensure that you return the arrays in this order\n",
    "    \"\"\"\n",
    "\n",
    "    # # TIP: use the train_test_split() function to partition your data. For example:\n",
    "    # X_train, X_test, y_train, y_test = train_test_split( \n",
    "    #                                     #TODO: provide the data, \n",
    "    #                                     #TODO: set the test set size,\n",
    "    #                                     #TODO: ensure stratified samples,\n",
    "    #                                     #TODO: ensure reproducible partitions\n",
    "    #                                     ) \n",
    "\n",
    "    # Split the data (i.e. X and y) into 80% train and 20% test, ensuring partitions are stratified and reproducible\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                                        X,                  #the input features\n",
    "                                                        y,                  #the label\n",
    "                                                        test_size=0.2,      #set aside 20% of the data as the test set  \n",
    "                                                        random_state=seed,  #reproduce the results\n",
    "                                                        stratify=y          #preserve the distribution of the labels\n",
    "                                                        )\n",
    "    \n",
    "    # Return the resulting features for X_train and X_test and the labels for y_train and y_test\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3e2fc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train data: [[7.4 2.8 6.1 1.9]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.3 3.3 6.  2.5]]\n",
      "-------------------------------------\n",
      "X_test data: [[6.2 2.8 4.8 1.8]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [6.3 2.9 5.6 1.8]]\n",
      "-------------------------------------\n",
      "y_train data: [2 0 2 2 2]\n",
      "-------------------------------------\n",
      "y_test data: [2 0 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "#DO NOT DELETE THIS CELL\n",
    "#test the function\n",
    "X_train, X_test, y_train, y_test = partition_data(X, y, SEED) # DO NOT DELETE OR MODIFY THIS LINE\n",
    "\n",
    "#view samples from the data\n",
    "print('X_train data: {}'.format(X_train[0:5]))\n",
    "print('-------------------------------------')\n",
    "print('X_test data: {}'.format(X_test[0:5]))\n",
    "print('-------------------------------------')\n",
    "print('y_train data: {}'.format(y_train[0:5]))\n",
    "print('-------------------------------------')\n",
    "print('y_test data: {}'.format(y_test[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36c54f54",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7f82876a79341f4ffd66feb8dcc8aa0",
     "grade": true,
     "grade_id": "partition_data_test",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#DO NOT DELETE THIS CELL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7ccae0",
   "metadata": {},
   "source": [
    "### Question 3: Train your classification tree (3 pts)\n",
    "Complete the function `build_classifier(...)` to build a decision tree classifier that predicts the type of iris flower. The function takes as input the partitioned data and a `seed`; and it returns the predicitons. Ensure that you perform the following steps inside the function:\n",
    "- Instantiate a DecisionTreeClassifier with **maximum_depth** = 3, **criterion** = 'entropy' and set the **random_state** to ensure reproducible results. [Click here to view the documentation for the decision tree classifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html).\n",
    "- Fit the decision tree to the training data\n",
    "- Predict the test set labels and assign the result to y_pred.\n",
    "- Return the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97f4edb3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "486e3076fa68e53f8aa37d56ec013d72",
     "grade": false,
     "grade_id": "build_classifier",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def build_classifier(X_train: np.ndarray, X_test: np.ndarray, y_train: np.ndarray, y_test: np.ndarray, seed: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Input numpy arrays for the partitioned train and test sets, and an integer seed.\n",
    "\n",
    "    Parameters:\n",
    "    - X_train (np.ndarray): a numpy array that contains the explanatory variables in the training set\n",
    "    - y_train (np.ndarray): a numpy array that contains the target variables in the training set\n",
    "    - X_test (np.ndarray): a numpy array that contains the explanatory variables in the test set\n",
    "    - y_test (np.ndarray): a numpy array that contains the target variables in the test set\n",
    "    - seed: the random state for reproducibilty\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: y_pred\n",
    "    \"\"\"\n",
    "\n",
    "    # Instantiate a DecisionTreeClassifier with maximum_depth = 3, criterion = 'entropy' and set the random_state to ensure reproducible results\n",
    "    dt = DecisionTreeClassifier(max_depth=3, criterion='entropy', random_state=seed)\n",
    "    \n",
    "    # Fit the decision tree to the training data\n",
    "    dt.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test set labels and assign the result to y_pred\n",
    "    y_pred = dt.predict(X_test)\n",
    "    \n",
    "    # Return the predictions\n",
    "    return y_pred\n",
    "    \n",
    "    raise NotImplementedError()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b5b4983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predictions are:  [1 0 0 1 2 1 2 0 2 2 1 0 0 1 1 1 0 0 1 1 2 0 1 0 2 2 2 1 0 2]\n"
     ]
    }
   ],
   "source": [
    "#print the predictions \n",
    "predictions = build_classifier(X_train, X_test, y_train, y_test, SEED)\n",
    "print(\"The predictions are: \", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fc1d3a6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "44e89e3170da8b05e272ceed3fab8ae4",
     "grade": true,
     "grade_id": "build_classifier_test",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#DO NOT DELETE THIS CELL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3d5860",
   "metadata": {},
   "source": [
    "### Question 4: Evaluate the model (1 pts)\n",
    "Now that you have fit your first classification tree, let's evaluate its performance on the test set using the accuracy metric. Complete the function `evaluate_model(...)` to evaluate the predicted labels with the actual labels. The function takes as input the predicted labels and the expected labels. Ensure that you perform the following steps inside the function:\n",
    "- Calculate the **accuracy** of the results.\n",
    "- Round the calculation to 2 decimal places\n",
    "- Return the accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89a5fd21",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea257b749233a7478724ab6512d5ae7c",
     "grade": false,
     "grade_id": "evaluate_model",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(y_pred: np.ndarray, y_test: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Input numpy arrays for y_pred and y_test.\n",
    "\n",
    "    Parameters:\n",
    "    - y_test (np.ndarray): a numpy array that contains the expected labels for the test set\n",
    "    - y_pred (np.ndarray): a numpy array that contains the predicted labels for the test set\n",
    "\n",
    "    Returns:\n",
    "    - float: accuracy rounded to 2 decimal places\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the accuracy of the results and round the calculation to 2 decimal places\n",
    "    accuracy = round(accuracy_score(y_test, y_pred), 2)\n",
    "    \n",
    "    # Return the accuracy\n",
    "    return accuracy\n",
    "\n",
    "    raise NotImplementedError()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4bc1010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "#print accuracy \n",
    "score = evaluate_model(predictions, y_test)\n",
    "print(\"Test set accuracy: {:.2f}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df22ae16",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "37e7c6a17413f0c714b0a6365f69bd5a",
     "grade": true,
     "grade_id": "evaluate_model_test",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#DO NOT DELETE THIS CELL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b7c1be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80b317ce",
   "metadata": {},
   "source": [
    "**Good job with the lab!** You have learned how to create a classification tree, using the same dataset from your k-nn assignment. Next, you will build a regression tree in the assignment.\n",
    "\n",
    "`Consider the following:` Did your decision tree perform better than k-nn using this dataset? While you are not required to submit a response to this question, keep in mind that algorithms' performance will vary depnding on the dataset. This is the reason we often experiment with different techniques. This experimentation will be cruicial in your Data Science project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac451eb6",
   "metadata": {},
   "source": [
    "### Additional Resource:\n",
    "\n",
    "#### [1. Scikit-learn Decision Tree Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "#### [2. Scikit-learn Accuracy Score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
